{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Train and save a servable TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzLKpmZICaWN",
    "outputId": "19c8f8a8-18f3-4cc8-8461-fcbc0bb39947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pLCLwMPq6Ufc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jAk1ZXqTJqN"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "### Import the banking dataset to detect churn activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m6BQd6gp6Ufd"
   },
   "outputs": [],
   "source": [
    "#importing the data\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/AdeloreSimiloluwa/Artificial-Neural-Network/master/data/Churn_Modelling.csv\")\n",
    "# data = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0FHgI2iu6Ufe"
   },
   "outputs": [],
   "source": [
    "#dropping some columns that are not needed\n",
    "data = data.drop(columns=['RowNumber','CustomerId','Surname'], axis=1)\n",
    "\n",
    "#split data into features #target data\n",
    "X, y  = data.iloc[:,:-1], data.iloc[:,-1:]\n",
    "\n",
    "\n",
    "#encoding the categorical columns\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder()\n",
    "X['Gender'] = le.fit_transform(X['Gender'])\n",
    "geo_df = pd.DataFrame(ohe.fit_transform(X[['Geography']]).toarray())\n",
    "\n",
    "#getting feature name after onehotencoding\n",
    "geo_df.columns = ohe.get_feature_names(['Geography'])\n",
    "\n",
    "#merging geo_df with the main data\n",
    "X = X.join(geo_df)\n",
    "\n",
    "#dropping the old columns after encoding\n",
    "X.drop(columns=['Geography'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ry1lua0c6Ufe"
   },
   "outputs": [],
   "source": [
    "#Split data into train and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split( X,y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LN_o5A76Ufe",
    "outputId": "3182ace6-a19d-47c8-8c52-f119fd5c1985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (8000, 12)\n",
      "The shape of X_test is (2000, 12)\n",
      "The shape of y_train is (8000, 1)\n",
      "The shape of y_test is (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "data_dict = {\"X_train\":X_train, \"X_test\":X_test, \"y_train\":y_train, \"y_test\":y_test}\n",
    "for i in data_dict:\n",
    "    print(\"The shape of {} is {}\".format(i,data_dict[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "u6IYewMu6Uff"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc =StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDu7OX8Nf5PY"
   },
   "source": [
    "### Train and evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68jadjpR6Ufg"
   },
   "source": [
    "#### Deep learning model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ri8raCeSBWRQ",
    "outputId": "1f10f9d3-2e71-465b-90ce-2bb880e43e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                208       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 353\n",
      "Trainable params: 353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#initializing the classifier model with its input, hidden and output layers\n",
    "classifier = keras.Sequential([\n",
    "                          keras.layers.Dense(units =16, input_dim=12, kernel_initializer='uniform', activation='relu'),\n",
    "                          keras.layers.Dense(units =8, kernel_initializer='uniform', activation='relu'),\n",
    "                          keras.layers.Dense(units =1, kernel_initializer='uniform', activation='sigmoid')\n",
    "])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6d6WTNl6Ufg",
    "outputId": "b484e97b-e03d-4f6e-d613-0a68a6d1fc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7922\n",
      "Epoch 2/5\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.4365 - accuracy: 0.7918\n",
      "Epoch 3/5\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4215 - accuracy: 0.8094\n",
      "Epoch 4/5\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4282 - accuracy: 0.8168\n",
      "Epoch 5/5\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4152 - accuracy: 0.8301\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8310\n",
      "\n",
      "Test accuracy: 0.8309999704360962\n"
     ]
    }
   ],
   "source": [
    "### Compiling the classifier model with Stochastic Gradient Desecnt\n",
    "classifier.compile(optimizer = 'adam', loss='binary_crossentropy' , metrics =['accuracy'])\n",
    "### Fitting the classifier model\n",
    "classifier.fit(X_train, y_train, batch_size=10 , epochs=5)\n",
    "\n",
    "test_loss, test_acc = classifier.evaluate(X_test,y_test)\n",
    "print('\\nTest accuracy: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwGPItyphqXT"
   },
   "source": [
    "## Save your model\n",
    "\n",
    "To load our trained model into TensorFlow Serving we first need to save it in [SavedModel](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/saved_model) format.  This will create a protobuf file in a well-defined directory hierarchy, and will include a version number.  [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) allows us to select which version of a model, or \"servable\" we want to use when we make inference requests.  Each version will be exported to a different sub-directory under the given path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0w5Rq8SsgWE6",
    "outputId": "c1ef267f-7bf9-467d-d88a-d314626547d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = /tmp/1\n",
      "\n",
      "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
      "\n",
      "Saved model:\n",
      "total 100\n",
      "drwxr-xr-x 2 twarik twarik  4096 Feb  2 14:32 assets\n",
      "-rw-r--r-- 1 twarik twarik 91204 Feb  6 01:18 saved_model.pb\n",
      "drwxr-xr-x 2 twarik twarik  4096 Feb  6 01:18 variables\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    classifier,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM7B_RuDYoIj"
   },
   "source": [
    "## Examine our saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LU4GDF_aYtfQ",
    "outputId": "9e4ade2a-67a4-4fa1-edd2-7683def6692b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-06 01:19:00.003846: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-02-06 01:19:00.003888: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['dense_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 12)\n",
      "        name: serving_default_dense_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_2'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 12), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 12), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 12), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 12), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 12), dtype=tf.float32, name='dense_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 12), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 12), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 12), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 12), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of train_and_serve_a_customer_churn_model_with_TensorFlow_Serving.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
