{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3kTSBokYppj"
   },
   "source": [
    "# Training on MNIST Dataset using Pytorch Operator\n",
    "\n",
    "Using PyTorch to build a model with two convolutional layers and two fully connected layers to perform the multi-class classification of images provided.\n",
    "\n",
    "\n",
    "### Requirement\n",
    "All you need is this notebook running in Kubeflow Notebook Server once you have cloned this repo\n",
    "You can use the pre-packaged Docker image here but if  you choose to build your own docker image, you must also have a Docker client installed on your machine.\n",
    "\n",
    "## Prerequisites\n",
    "Before we proceed, check to see if Pytorch is already installed in your Notebook Server Environment or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsYow3NYYppm",
    "outputId": "56c377a1-cb29-4a23-bb66-4157351cfad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.8.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.6.3)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (4.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (7.16.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.18.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.28.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (4.59.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (5.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (3.15.6)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (2.22.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (20.3.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.3.3)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.9.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (0.8)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets) (3.7.4.3)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.7)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.0.10)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.7.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (46.1.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.1.5)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.52.0)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets) (3.1.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2020.4.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (19.0.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.2.1)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.3)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.8.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep torch\n",
    "! pip3 install ipywidgets \n",
    "! pip3 install torch torchvision matplotlib --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jizay5ufYppm"
   },
   "source": [
    "To get started package the trainer in a Docker container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dxT2m8MgYppn"
   },
   "outputs": [],
   "source": [
    "TRAINER_FILE = \"mnist.py\"\n",
    "KUBERNETES_FILE = \"pytorchjob-mnist.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41CYOCqxYppn"
   },
   "source": [
    "We also want to capture output from a cell with [`%%capture`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-capture) that usually looks like `some-resource created`.\n",
    "To that end, let's define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n37Cpbl3Yppn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from IPython.utils.capture import CapturedIO\n",
    "\n",
    "\n",
    "def get_resource(captured_io: CapturedIO) -> str:\n",
    "    \"\"\"\n",
    "    Gets a resource name from `kubectl apply -f <configuration.yaml>`.\n",
    "\n",
    "    :param str captured_io: Output captured by using `%%capture` cell magic\n",
    "    :return: Name of the Kubernetes resource\n",
    "    :rtype: str\n",
    "    :raises Exception: if the resource could not be created\n",
    "    \"\"\"\n",
    "    out = captured_io.stdout\n",
    "    matches = re.search(r\"^(.+)\\s+created\", out)\n",
    "    if matches is not None:\n",
    "        return matches.group(1)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Cannot get resource as its creation failed: {out}. It may already exist.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WljMQNaSYppn"
   },
   "source": [
    "## Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjhDcx6vYppn",
    "outputId": "242b429f-b659-4d9f-aab8-0d8de7214de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-17 07:43:43--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
      "--2021-03-17 07:43:43--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘MNIST.tar.gz.2’\n",
      "\n",
      "MNIST.tar.gz.2          [              <=>   ]  33.20M  12.1MB/s    in 2.7s    \n",
      "\n",
      "2021-03-17 07:43:46 (12.1 MB/s) - ‘MNIST.tar.gz.2’ saved [34813078]\n",
      "\n",
      "MNIST/\n",
      "MNIST/raw/\n",
      "MNIST/raw/train-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "MNIST/raw/train-images-idx3-ubyte\n",
      "MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-images-idx3-ubyte\n",
      "MNIST/raw/train-images-idx3-ubyte.gz\n",
      "MNIST/processed/\n",
      "MNIST/processed/training.pt\n",
      "MNIST/processed/test.pt\n"
     ]
    }
   ],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGEV1PBnYppn"
   },
   "source": [
    "## How to Load and Inspect the Data\n",
    "Initialize Torch with the downloaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfSb039rYppn",
    "outputId": "c53b7172-7c4e-4dc6-a449-b88a9ea376a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./\n",
       "    Split: Train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "root_dir = './'\n",
    "torchvision.datasets.MNIST(root=root_dir,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAHASqodYppo",
    "outputId": "9140fba0-c2d5-4306-cea5-0decc3591ae8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# See: https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.MNIST\n",
    "mnist = datasets.MNIST(\"./\", download=True, train=True, transform=transforms.ToTensor())\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8Eg6V7vYppo",
    "outputId": "70dc7ae2-0dc8-4728-85ca-e734523629de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60000, 28, 28]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mnist.data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzGSe4c2Yppo"
   },
   "source": [
    "We are therefore dealing with 60,000 28x28 pixel greyscale images.\n",
    "These have not yet been scaled into the [0, 1] range, as we can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEH1hihAYppo",
    "outputId": "8fe7ea06-c08a-4d32-cc37-64497c6961b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(255.))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.float().min(), mnist.data.float().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4ets0wgDYppo"
   },
   "outputs": [],
   "source": [
    "# See: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
    "example, example_label = mnist.__getitem__(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ROy-MxkVYppo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "VZtlzMoHYppo",
    "outputId": "ac0ffe58-9552-4a2f-cfa4-213f328998f8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMvUlEQVR4nO3dX4xcd3nG8eex8Z9gMPHadGscqwHHtIqQcNDKoSLQpFFRkqI6UBHFrVIjRSwViUQkLojSC9L2xkJAhKo20qaxYhA1QgpRfBEVjEWJQJXJJrixE1PshI1is/ESXDWGNI69fnuxx2jj7Px2PefMnEne70dazcx55+x5deRnz5/fjH+OCAF481vUdgMA+oOwA0kQdiAJwg4kQdiBJN7Sz40t9bJYrhX93CSQyiv6rV6NU56rVivstq+T9DVJiyX9a0RsL71/uVboSl9bZ5MACvbF3o61rk/jbS+W9M+Srpd0uaStti/v9vcB6K061+ybJR2JiGcj4lVJ35K0pZm2ADStTtjXSXp+1uuj1bLXsD1qe9z2+GmdqrE5AHX0/G58RIxFxEhEjCzRsl5vDkAHdcJ+TNL6Wa8vqZYBGEB1wv6YpI223217qaSbJe1upi0ATet66C0izti+XdJ3NTP0tiMinmqsMwCNqjXOHhGPSHqkoV4A9BAflwWSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kUWvKZtsTkk5KmpZ0JiJGmmgKQPNqhb1yTUS82MDvAdBDnMYDSdQNe0j6nu3HbY/O9Qbbo7bHbY+f1qmamwPQrbqn8VdFxDHbvydpj+2fRcSjs98QEWOSxiRppYei5vYAdKnWkT0ijlWPU5IekrS5iaYANK/rsNteYfvt555L+qikg001BqBZdU7jhyU9ZPvc7/m3iPj3RroC0Liuwx4Rz0p6f4O9AOghht6AJAg7kARhB5Ig7EAShB1IookvwuCNbGbotKPFGy4t1n/x12uL9Y/8+U871rau3ldc90sf+8tiffrQ4WIdr8WRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9TWDxezd0rE18cri47oe3dB4Hl6R/WfdgVz0txOT0y8W6T5bruDAc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZB8DZqzYV6ye+UB5v/v6mBzrWVi5aXlz3wd+uKtY37vl0se63nC3Wf37N/R1rf3XoluK6Fx39RbGOC8ORHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9AS9/4spi/Y7tu4r1D1/042J99aKLivU/+uFnO9betWtpcd0VP/xZsb7xpceL9bN/ckWxrms6l44dKn/X/jIxzt6keY/stnfYnrJ9cNayIdt7bB+uHsufzADQuoWcxj8g6brzlt0paW9EbJS0t3oNYIDNG/aIeFTSifMWb5G0s3q+U9KNzbYFoGndXrMPR8Rk9fwFSR0vvmyPShqVpOV6a5ebA1BX7bvxERGSolAfi4iRiBhZomV1NwegS92G/bjttZJUPU411xKAXug27Lslbaueb5P0cDPtAOiVea/Zbe+SdLWkNbaPSvqipO2Svm37VknPSbqpl00OupfXlP9m/tPEnxbr//ByeRx96cMXF+vv2fmTzsWz08V1y9XeWvxKeW54NGvesEfE1g6laxvuBUAP8XFZIAnCDiRB2IEkCDuQBGEHkuArrg1YM/af5TeMlcu/31wrfbfs71/oet3L7nmmWG9zWPDNiCM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBODtq+eAQ/93zGwVHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnF29NRdUx/oWDv76/OnEEQvcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0fR4vduKNZvW/WNYv36A3/TsfaOM0e66gndmffIbnuH7SnbB2ctu9v2Mdv7q58betsmgLoWchr/gKTr5lh+T0Rsqn4eabYtAE2bN+wR8agkPtcIvMHVuUF3u+0nq9P8VZ3eZHvU9rjt8dM6VWNzAOroNuz3StogaZOkSUlf6fTGiBiLiJGIGFmiZV1uDkBdXYU9Io5HxHREnJV0n6TNzbYFoGldhd322lkvPy7pYKf3AhgM846z294l6WpJa2wflfRFSVfb3iQpJE1I+kzvWkSbJj45XKyvXLS8WF9271CT7aCGecMeEVvnWHx/D3oB0EN8XBZIgrADSRB2IAnCDiRB2IEk+IoripZf+eti/Yymi/UVR/6nY628JprGkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUXve+dksb79xfcX69OHDjfZDmrgyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ8H325BavWV2sf/mS3cX6Zye2zLOFFy+wI/TKvEd22+tt/8D207afsv25avmQ7T22D1ePq3rfLoBuLeQ0/oykz0fE5ZI+KOk225dLulPS3ojYKGlv9RrAgJo37BExGRFPVM9PSjokaZ2kLZJ2Vm/bKenGHvUIoAEXdM1u+1JJV0jaJ2k4Is79B2UvSBrusM6opFFJWq63dt0ogHoWfDfe9tskPSjpjoh4aXYtIkJSzLVeRIxFxEhEjCzRslrNAujegsJue4lmgv7NiPhOtfi47bVVfa2kqd60CKAJ857G27ak+yUdioivzirtlrRN0vbq8eGedIiemrz5D4v11YsuKtafv29jsX4xQ28DYyHX7B+SdIukA7b3V8vu0kzIv237VknPSbqpJx0CaMS8YY+IH0lyh/K1zbYDoFf4uCyQBGEHkiDsQBKEHUiCsANJ8BXX5N7xF7+stf7K515pqBP0Gkd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcXYUPXPm/4r1Jb/832J9uslmUAtHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH25G6+5LFiff+pdxXr04efbbId9BBHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IYiHzs6+X9HVJw5JC0lhEfM323ZI+LelX1VvviohHetUoujPxj39crP/txfcW65f9x6eK9Q3af4EdoS0L+VDNGUmfj4gnbL9d0uO291S1eyLiy71rD0BTFjI/+6Skyer5SduHJK3rdWMAmnVB1+y2L5V0haR91aLbbT9pe4ftVR3WGbU9bnv8tE7V6xZA1xYcdttvk/SgpDsi4iVJ90raIGmTZo78X5lrvYgYi4iRiBhZomX1OwbQlQWF3fYSzQT9mxHxHUmKiOMRMR0RZyXdJ2lz79oEUNe8YbdtSfdLOhQRX521fO2st31c0sHm2wPQlIXcjf+QpFskHbC9v1p2l6SttjdpZjhuQtJnetAfajo9dLbW+sMPcen1ZrGQu/E/kuQ5SoypA28gfIIOSIKwA0kQdiAJwg4kQdiBJAg7kIQjom8bW+mhuNLX9m17QDb7Yq9eihNzDZVzZAeyIOxAEoQdSIKwA0kQdiAJwg4kQdiBJPo6zm77V5Kem7VojaQX+9bAhRnU3ga1L4neutVkb38QEe+cq9DXsL9u4/Z4RIy01kDBoPY2qH1J9NatfvXGaTyQBGEHkmg77GMtb79kUHsb1L4keutWX3pr9ZodQP+0fWQH0CeEHUiilbDbvs72f9s+YvvONnroxPaE7QO299seb7mXHbanbB+ctWzI9h7bh6vHOefYa6m3u20fq/bdfts3tNTbets/sP207adsf65a3uq+K/TVl/3W92t224sl/VzSn0k6KukxSVsj4um+NtKB7QlJIxHR+gcwbH9E0m8kfT0i3lct+5KkExGxvfpDuSoivjAgvd0t6TdtT+NdzVa0dvY045JulPQptbjvCn3dpD7stzaO7JslHYmIZyPiVUnfkrSlhT4GXkQ8KunEeYu3SNpZPd+pmX8sfdeht4EQEZMR8UT1/KSkc9OMt7rvCn31RRthXyfp+Vmvj2qw5nsPSd+z/bjt0babmcNwRExWz1+QNNxmM3OYdxrvfjpvmvGB2XfdTH9eFzfoXu+qiPiApOsl3Vadrg6kmLkGG6Sx0wVN490vc0wz/jtt7rtupz+vq42wH5O0ftbrS6plAyEijlWPU5Ie0uBNRX383Ay61eNUy/38ziBN4z3XNOMagH3X5vTnbYT9MUkbbb/b9lJJN0va3UIfr2N7RXXjRLZXSPqoBm8q6t2StlXPt0l6uMVeXmNQpvHuNM24Wt53rU9/HhF9/5F0g2buyD8j6e/a6KFDX++R9F/Vz1Nt9yZpl2ZO605r5t7GrZJWS9or6bCk70saGqDeviHpgKQnNROstS31dpVmTtGflLS/+rmh7X1X6Ksv+42PywJJcIMOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4f2zmwWmlwqgBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.squeeze(example))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4e52X-_Yppo"
   },
   "source": [
    "The corresponding label is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dk2xPF1mYppp",
    "outputId": "af5e46db-b3e9-49c0-cf98-72bb7aa0e67a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31AGx6fhYppp"
   },
   "source": [
    "We shall normalize the data set (to improve the training speed), which means we need to know the mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXfg9haoYppp",
    "outputId": "c0cdaa69-20d4-4394-8fe9-41947fc0c906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1307), tensor(0.3081))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.float().mean() / 255, mnist.data.float().std() / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfdgqpjNYppp"
   },
   "source": [
    "These are the values we will hard-code in our transformations within the model.\n",
    "Ideally, we re-compute these based on the training data set to ensure we capture the correct values when the underlying data changes.\n",
    "Our data set is static, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uQI3PrqDYppp"
   },
   "outputs": [],
   "source": [
    "# Clear variables as we have no need for these any longer\n",
    "del mnist, example, example_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wFTMB_QCYppp",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcjMjdW7Yppp"
   },
   "source": [
    "## How to Train the Model in the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZXwapk3Yppp"
   },
   "source": [
    "Since we ultimately want to train the model in a distributed mode, we put all the code in a single cell.\n",
    "That way we can save the file and include it in a container image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knz90zUmYppp",
    "outputId": "3cbd39a3-2398-4f2d-8a62-e074dc8eb976",
    "tags": [
     "trainer_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $TRAINER_FILE\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Number of processes participating in (distributed) job\n",
    "# See: https://pytorch.org/docs/stable/distributed.html\n",
    "WORLD_SIZE = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "\n",
    "\n",
    "# Custom models must subclass toch.nn.Module and override `forward`\n",
    "# See: https://pytorch.org/docs/stable/nn.html#torch.nn.Module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def should_distribute():\n",
    "    return dist.is_available() and WORLD_SIZE > 1\n",
    "\n",
    "\n",
    "def is_distributed():\n",
    "    return dist.is_available() and dist.is_initialized()\n",
    "\n",
    "\n",
    "def percentage(value):\n",
    "    return \"{: 5.1f}%\".format(100.0 * value)\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch} ({percentage(batch_idx / len(train_loader))}) - Loss: {loss.item()}\"\n",
    "            )\n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum batch losses\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    logging.info(\n",
    "        f\"Test accuracy: {correct}/{len(test_loader.dataset)} ({percentage(correct / len(test_loader.dataset))})\"\n",
    "    )\n",
    "\n",
    "    # Log metrics for Katib\n",
    "    logging.info(\"loss={:.4f}\".format(test_loss))\n",
    "    logging.info(\"accuracy={:.4f}\".format(float(correct) / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch MNIST Training Job\")\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        metavar=\"N\",\n",
    "        help=\"Batch size for training (default: 64)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test-batch-size\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        metavar=\"N\",\n",
    "        help=\"Batch size for testing (default: 1000)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        metavar=\"N\",\n",
    "        help=\"Number of epochs to train\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        default=1.0,\n",
    "        metavar=\"LR\",\n",
    "        help=\"Learning rate (default: 1.0)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gamma\",\n",
    "        type=float,\n",
    "        default=0.7,\n",
    "        metavar=\"M\",\n",
    "        help=\"Learning rate's decay rate (default: 0.7)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-cuda\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Disables CUDA (GPU) training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--seed\", type=int, default=1, metavar=\"S\", help=\"Random seed (default: 1)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--log-interval\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        metavar=\"N\",\n",
    "        help=\"Number of training batches between status log entries\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save-model\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Whether to save the trained model\",\n",
    "    )\n",
    "\n",
    "    if dist.is_available():\n",
    "        parser.add_argument(\n",
    "            \"--backend\",\n",
    "            type=str,\n",
    "            help=\"Distributed backend\",\n",
    "            choices=[dist.Backend.GLOO, dist.Backend.NCCL, dist.Backend.MPI],\n",
    "            default=dist.Backend.GLOO,\n",
    "        )\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    if should_distribute():\n",
    "        logging.debug(\"Using distributed PyTorch with {} backend\".format(args.backend))\n",
    "        dist.init_process_group(backend=args.backend)\n",
    "\n",
    "    kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
    "    train_data = datasets.MNIST(\n",
    "        \"./\",\n",
    "        download=False,\n",
    "        train=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # DistributedSampler partitions the training dataset among the worker processes\n",
    "    train_sampler = (\n",
    "        torch.utils.data.distributed.DistributedSampler(train_data)\n",
    "        if should_distribute()\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        shuffle=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            \"./\",\n",
    "            download=False,\n",
    "            train=False,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = Net().to(device)\n",
    "\n",
    "    if is_distributed():\n",
    "        if use_cuda:\n",
    "            torch.cuda.set_device(torch.cuda.current_device())\n",
    "        model = nn.parallel.DistributedDataParallel(model)\n",
    "\n",
    "    # See: https://pytorch.org/docs/stable/optim.html#torch.optim.Adadelta\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # See: https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.StepLR\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_model.pt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlrP6HLkYpps"
   },
   "source": [
    "Let's see if our code is correct by running it from within our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "id": "XoKrW93GYppu",
    "outputId": "44ab19db-8743-4f79-b1d9-7485afafe3f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 1 (  0.0%) - Loss: 2.29303240776062\n",
      "INFO:root:Epoch: 1 ( 13.6%) - Loss: 0.5207589864730835\n",
      "INFO:root:Epoch: 1 ( 27.3%) - Loss: 0.07054267078638077\n",
      "INFO:root:Epoch: 1 ( 40.9%) - Loss: 0.19108931720256805\n",
      "INFO:root:Epoch: 1 ( 54.6%) - Loss: 0.37162208557128906\n",
      "INFO:root:Epoch: 1 ( 68.2%) - Loss: 0.08093594014644623\n",
      "INFO:root:Epoch: 1 ( 81.9%) - Loss: 0.3664531111717224\n",
      "INFO:root:Epoch: 1 ( 95.5%) - Loss: 0.03546219691634178\n",
      "INFO:root:Test accuracy: 9838/10000 ( 98.4%)\n",
      "INFO:root:loss=0.0486\n",
      "INFO:root:accuracy=0.9838\n",
      "INFO:root:Epoch: 2 (  0.0%) - Loss: 0.08004315942525864\n",
      "INFO:root:Epoch: 2 ( 13.6%) - Loss: 0.25475379824638367\n",
      "INFO:root:Epoch: 2 ( 27.3%) - Loss: 0.009925932623445988\n",
      "INFO:root:Epoch: 2 ( 40.9%) - Loss: 0.09941373765468597\n",
      "INFO:root:Epoch: 2 ( 54.6%) - Loss: 0.20104627311229706\n",
      "INFO:root:Epoch: 2 ( 68.2%) - Loss: 0.06250841170549393\n",
      "INFO:root:Epoch: 2 ( 81.9%) - Loss: 0.10338491201400757\n",
      "INFO:root:Epoch: 2 ( 95.5%) - Loss: 0.009137551300227642\n",
      "INFO:root:Test accuracy: 9872/10000 ( 98.7%)\n",
      "INFO:root:loss=0.0397\n",
      "INFO:root:accuracy=0.9872\n",
      "INFO:root:Epoch: 3 (  0.0%) - Loss: 0.06143474951386452\n",
      "INFO:root:Epoch: 3 ( 13.6%) - Loss: 0.19064536690711975\n",
      "INFO:root:Epoch: 3 ( 27.3%) - Loss: 0.026811685413122177\n",
      "INFO:root:Epoch: 3 ( 40.9%) - Loss: 0.11851559579372406\n",
      "INFO:root:Epoch: 3 ( 54.6%) - Loss: 0.04274458810687065\n",
      "INFO:root:Epoch: 3 ( 68.2%) - Loss: 0.02688281424343586\n",
      "INFO:root:Epoch: 3 ( 81.9%) - Loss: 0.14260347187519073\n",
      "INFO:root:Epoch: 3 ( 95.5%) - Loss: 0.0421033576130867\n",
      "INFO:root:Test accuracy: 9885/10000 ( 98.9%)\n",
      "INFO:root:loss=0.0320\n",
      "INFO:root:accuracy=0.9885\n",
      "INFO:root:Epoch: 4 (  0.0%) - Loss: 0.029034772887825966\n",
      "INFO:root:Epoch: 4 ( 13.6%) - Loss: 0.1653074026107788\n",
      "INFO:root:Epoch: 4 ( 27.3%) - Loss: 0.0011595647083595395\n",
      "INFO:root:Epoch: 4 ( 40.9%) - Loss: 0.0950222909450531\n",
      "INFO:root:Epoch: 4 ( 54.6%) - Loss: 0.010067296214401722\n",
      "INFO:root:Epoch: 4 ( 68.2%) - Loss: 0.028676630929112434\n",
      "INFO:root:Epoch: 4 ( 81.9%) - Loss: 0.049560658633708954\n",
      "INFO:root:Epoch: 4 ( 95.5%) - Loss: 0.014001487754285336\n",
      "INFO:root:Test accuracy: 9887/10000 ( 98.9%)\n",
      "INFO:root:loss=0.0317\n",
      "INFO:root:accuracy=0.9887\n",
      "INFO:root:Epoch: 5 (  0.0%) - Loss: 0.09386748820543289\n",
      "INFO:root:Epoch: 5 ( 13.6%) - Loss: 0.1624368131160736\n",
      "INFO:root:Epoch: 5 ( 27.3%) - Loss: 0.008069842122495174\n",
      "INFO:root:Epoch: 5 ( 40.9%) - Loss: 0.03662287816405296\n",
      "INFO:root:Epoch: 5 ( 54.6%) - Loss: 0.0672035738825798\n",
      "INFO:root:Epoch: 5 ( 68.2%) - Loss: 0.024266839027404785\n",
      "INFO:root:Epoch: 5 ( 81.9%) - Loss: 0.07653389126062393\n",
      "INFO:root:Epoch: 5 ( 95.5%) - Loss: 0.007416411302983761\n",
      "INFO:root:Test accuracy: 9892/10000 ( 98.9%)\n",
      "INFO:root:loss=0.0293\n",
      "INFO:root:accuracy=0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run $TRAINER_FILE --epochs $epochs --log-interval 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93EoP7GpYppu",
    "tags": [
     "trainer_dockerfile"
    ]
   },
   "source": [
    "The Dockerfile looks as follows:\n",
    "\n",
    "```\n",
    "FROM mavencodev/pytorch_job:1.0\n",
    "ADD mnist.py /\n",
    "ADD datasets /datasets\n",
    "\n",
    "ENTRYPOINT [\"python\", \"/mnist.py\"]\n",
    "```\n",
    "\n",
    "Then it's easy to push images to your container registry:\n",
    "\n",
    "```bash\n",
    "docker build -t <docker_image_name_with_tag> .\n",
    "docker push <docker_image_name_with_tag>\n",
    "```\n",
    "\n",
    "The image is available as `mavencodev/pytorch_job:1.0` in case you want to skip it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnz-nuPxYppu"
   },
   "source": [
    "## How to Create a Distributed `PyTorchJob`\n",
    "For large training jobs, we wish to run our trainer in a distributed mode.\n",
    "Once the notebook server cluster can access the Docker image from the registry, we can launch a distributed PyTorch job.\n",
    "\n",
    "The specification for a distributed `PyTorchJob` is defined using YAML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvpWcq3BYppu",
    "outputId": "5eacd493-d8f3-41b5-cf7d-e91279d91acb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pytorchjob-mnist.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $KUBERNETES_FILE\n",
    "apiVersion: \"kubeflow.org/v1\"\n",
    "kind: \"PyTorchJob\"\n",
    "metadata:\n",
    "  name: \"pytorchjob-mnist-1\"\n",
    "  namespace: \"demo01\"\n",
    "spec:\n",
    "  pytorchReplicaSpecs:\n",
    "    Master:\n",
    "      replicas: 1\n",
    "      restartPolicy: OnFailure\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          containers:\n",
    "            - name: pytorch\n",
    "              # modify this property if you would like to use a custom image\n",
    "              image: mesosphere/kubeflow:mnist-pytorch-1.0.1-0.6.0\n",
    "              # TODO: Add arguments as required!\n",
    "              args:\n",
    "                - --epochs\n",
    "                - \"15\"\n",
    "                - --seed\n",
    "                - \"7\"\n",
    "                - --log-interval\n",
    "                - \"256\"\n",
    "    Worker:\n",
    "      replicas: 2\n",
    "      restartPolicy: OnFailure\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          containers:\n",
    "            - name: pytorch\n",
    "              # modify this property if you like to use a custom image\n",
    "              image: mesosphere/kubeflow:mnist-pytorch-1.0.1-0.6.0\n",
    "              args:\n",
    "                # TODO: Add arguments as required!\n",
    "                - --epochs\n",
    "                - \"15\"\n",
    "                - --seed\n",
    "                - \"7\"\n",
    "                - --log-interval\n",
    "                - \"256\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ABkOY1LzYppu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture pytorch_output --no-stderr\n",
    "! kubectl create -f $KUBERNETES_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "tBGBMcvMYppu",
    "outputId": "fbf1b71e-07b1-45f8-a436-e631908f5181"
   },
   "outputs": [],
   "source": [
    "PYTORCH_JOB = get_resource(pytorch_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD8v4U3rYppu"
   },
   "source": [
    "We can check the status like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "F4sUQBbMYppu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         pytorchjob-mnist-1\n",
      "Namespace:    demo01\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "API Version:  kubeflow.org/v1\n",
      "Kind:         PyTorchJob\n",
      "Metadata:\n",
      "  Creation Timestamp:  2021-03-17T09:14:50Z\n",
      "  Generation:          1\n",
      "  Managed Fields:\n",
      "    API Version:  kubeflow.org/v1\n",
      "    Fields Type:  FieldsV1\n",
      "    fieldsV1:\n",
      "      f:spec:\n",
      "        .:\n",
      "        f:pytorchReplicaSpecs:\n",
      "          .:\n",
      "          f:Master:\n",
      "            .:\n",
      "            f:replicas:\n",
      "            f:restartPolicy:\n",
      "            f:template:\n",
      "              .:\n",
      "              f:metadata:\n",
      "                .:\n",
      "                f:annotations:\n",
      "                  .:\n",
      "                  f:sidecar.istio.io/inject:\n",
      "              f:spec:\n",
      "          f:Worker:\n",
      "            .:\n",
      "            f:replicas:\n",
      "            f:restartPolicy:\n",
      "            f:template:\n",
      "              .:\n",
      "              f:metadata:\n",
      "                .:\n",
      "                f:annotations:\n",
      "                  .:\n",
      "                  f:sidecar.istio.io/inject:\n",
      "              f:spec:\n",
      "    Manager:      kubectl-create\n",
      "    Operation:    Update\n",
      "    Time:         2021-03-17T09:14:50Z\n",
      "    API Version:  kubeflow.org/v1\n",
      "    Fields Type:  FieldsV1\n",
      "    fieldsV1:\n",
      "      f:spec:\n",
      "        f:cleanPodPolicy:\n",
      "        f:pytorchReplicaSpecs:\n",
      "          f:Master:\n",
      "            f:template:\n",
      "              f:metadata:\n",
      "                f:creationTimestamp:\n",
      "              f:spec:\n",
      "                f:containers:\n",
      "          f:Worker:\n",
      "            f:template:\n",
      "              f:metadata:\n",
      "                f:creationTimestamp:\n",
      "              f:spec:\n",
      "                f:containers:\n",
      "      f:status:\n",
      "        .:\n",
      "        f:conditions:\n",
      "        f:replicaStatuses:\n",
      "          .:\n",
      "          f:Master:\n",
      "          f:Worker:\n",
      "        f:startTime:\n",
      "    Manager:         pytorch-operator.v1\n",
      "    Operation:       Update\n",
      "    Time:            2021-03-17T09:14:52Z\n",
      "  Resource Version:  8332051\n",
      "  Self Link:         /apis/kubeflow.org/v1/namespaces/demo01/pytorchjobs/pytorchjob-mnist-1\n",
      "  UID:               8715b846-0033-4211-8f97-89bcbaca7875\n",
      "Spec:\n",
      "  Pytorch Replica Specs:\n",
      "    Master:\n",
      "      Replicas:        1\n",
      "      Restart Policy:  OnFailure\n",
      "      Template:\n",
      "        Metadata:\n",
      "          Annotations:\n",
      "            sidecar.istio.io/inject:  false\n",
      "        Spec:\n",
      "          Containers:\n",
      "            Args:\n",
      "              --epochs\n",
      "              15\n",
      "              --seed\n",
      "              7\n",
      "              --log-interval\n",
      "              256\n",
      "            Image:  mesosphere/kubeflow:mnist-pytorch-1.0.1-0.6.0\n",
      "            Name:   pytorch\n",
      "    Worker:\n",
      "      Replicas:        2\n",
      "      Restart Policy:  OnFailure\n",
      "      Template:\n",
      "        Metadata:\n",
      "          Annotations:\n",
      "            sidecar.istio.io/inject:  false\n",
      "        Spec:\n",
      "          Containers:\n",
      "            Args:\n",
      "              --epochs\n",
      "              15\n",
      "              --seed\n",
      "              7\n",
      "              --log-interval\n",
      "              256\n",
      "            Image:  mesosphere/kubeflow:mnist-pytorch-1.0.1-0.6.0\n",
      "            Name:   pytorch\n",
      "Status:\n",
      "  Conditions:\n",
      "    Last Transition Time:  2021-03-17T09:14:50Z\n",
      "    Last Update Time:      2021-03-17T09:14:50Z\n",
      "    Message:               PyTorchJob pytorchjob-mnist-1 is created.\n",
      "    Reason:                PyTorchJobCreated\n",
      "    Status:                True\n",
      "    Type:                  Created\n",
      "  Replica Statuses:\n",
      "    Master:\n",
      "    Worker:\n",
      "  Start Time:  2021-03-17T09:14:52Z\n",
      "Events:\n",
      "  Type    Reason                   Age   From              Message\n",
      "  ----    ------                   ----  ----              -------\n",
      "  Normal  SuccessfulCreatePod      2s    pytorch-operator  Created pod: pytorchjob-mnist-1-worker-0\n",
      "  Normal  SuccessfulCreatePod      1s    pytorch-operator  Created pod: pytorchjob-mnist-1-worker-1\n",
      "  Normal  SuccessfulCreatePod      1s    pytorch-operator  Created pod: pytorchjob-mnist-1-master-0\n",
      "  Normal  SuccessfulCreateService  1s    pytorch-operator  Created service: pytorchjob-mnist-1-master-0\n"
     ]
    }
   ],
   "source": [
    "! kubectl describe $PYTORCH_JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5WnUSkKYppv"
   },
   "source": [
    "The output roughly looks like this:\n",
    "\n",
    "```yaml\n",
    "Name:         pytorchjob-mnist\n",
    "...\n",
    "Kind:         PyTorchJob\n",
    "...\n",
    "Events:\n",
    "  Type    Reason                   Age   From              Message\n",
    "  ----    ------                   ----  ----              -------\n",
    "  Normal  SuccessfulCreatePod      8s    pytorch-operator  Created pod: pytorchjob-mnist-master-0\n",
    "  Normal  SuccessfulCreateService  8s    pytorch-operator  Created service: pytorchjob-mnist-master-0\n",
    "  Normal  SuccessfulCreatePod      8s    pytorch-operator  Created pod: pytorchjob-mnist-worker-0\n",
    "  Normal  SuccessfulCreatePod      8s    pytorch-operator  Created pod: pytorchjob-mnist-worker-1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2fds91oYppv"
   },
   "source": [
    "You should now be able to see the pods created, matching the specified number of replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FHrviZEmYppv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          READY   STATUS              RESTARTS   AGE\n",
      "pytorchjob-mnist-1-master-0   0/1     ContainerCreating   0          14s\n",
      "pytorchjob-mnist-1-worker-0   0/1     Init:0/1            0          15s\n",
      "pytorchjob-mnist-1-worker-1   0/1     Init:0/1            0          14s\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods -l job-name=pytorchjob-mnist-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrpp0vdCYppv"
   },
   "source": [
    "The job name matches `metadata.name` from the YAML.\n",
    "\n",
    "As per our specification, the training runs for 15 epochs.\n",
    "During that time, we can stream the logs from the `Master` pod to follow the progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "6xQiAR26Yppv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 1 (  0.0%) - Loss: 2.3082287311553955\n",
      "INFO:root:Epoch: 1 ( 81.8%) - Loss: 0.036284517496824265\n",
      "INFO:root:Test accuracy: 9823/10000 ( 98.2%)\n",
      "INFO:root:loss=0.0536\n",
      "INFO:root:accuracy=0.9823\n",
      "INFO:root:Epoch: 2 (  0.0%) - Loss: 0.09130682796239853\n",
      "INFO:root:Epoch: 2 ( 81.8%) - Loss: 0.024165796115994453\n",
      "INFO:root:Test accuracy: 9866/10000 ( 98.7%)\n",
      "INFO:root:loss=0.0371\n",
      "INFO:root:accuracy=0.9866\n",
      "INFO:root:Epoch: 3 (  0.0%) - Loss: 0.1300644725561142\n",
      "INFO:root:Epoch: 3 ( 81.8%) - Loss: 0.02042296528816223\n",
      "INFO:root:Test accuracy: 9873/10000 ( 98.7%)\n",
      "INFO:root:loss=0.0343\n",
      "INFO:root:accuracy=0.9873\n",
      "INFO:root:Epoch: 4 (  0.0%) - Loss: 0.06552477926015854\n",
      "INFO:root:Epoch: 4 ( 81.8%) - Loss: 0.05636398121714592\n",
      "INFO:root:Test accuracy: 9898/10000 ( 99.0%)\n",
      "INFO:root:loss=0.0313\n",
      "INFO:root:accuracy=0.9898\n",
      "INFO:root:Epoch: 5 (  0.0%) - Loss: 0.09892503917217255\n",
      "INFO:root:Epoch: 5 ( 81.8%) - Loss: 0.016372758895158768\n",
      "INFO:root:Test accuracy: 9899/10000 ( 99.0%)\n",
      "INFO:root:loss=0.0296\n",
      "INFO:root:accuracy=0.9899\n",
      "INFO:root:Epoch: 6 (  0.0%) - Loss: 0.018990186974406242\n",
      "INFO:root:Epoch: 6 ( 81.8%) - Loss: 0.005294940434396267\n",
      "INFO:root:Test accuracy: 9897/10000 ( 99.0%)\n",
      "INFO:root:loss=0.0282\n",
      "INFO:root:accuracy=0.9897\n",
      "INFO:root:Epoch: 7 (  0.0%) - Loss: 0.030664723366498947\n",
      "INFO:root:Epoch: 7 ( 81.8%) - Loss: 0.006755029782652855\n",
      "INFO:root:Test accuracy: 9905/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0272\n",
      "INFO:root:accuracy=0.9905\n",
      "INFO:root:Epoch: 8 (  0.0%) - Loss: 0.02368374913930893\n",
      "INFO:root:Epoch: 8 ( 81.8%) - Loss: 0.0012680887011811137\n",
      "INFO:root:Test accuracy: 9912/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0267\n",
      "INFO:root:accuracy=0.9912\n",
      "INFO:root:Epoch: 9 (  0.0%) - Loss: 0.009861034341156483\n",
      "INFO:root:Epoch: 9 ( 81.8%) - Loss: 0.0038052969612181187\n",
      "INFO:root:Test accuracy: 9913/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0269\n",
      "INFO:root:accuracy=0.9913\n",
      "INFO:root:Epoch: 10 (  0.0%) - Loss: 0.033784303814172745\n",
      "INFO:root:Epoch: 10 ( 81.8%) - Loss: 0.006071601994335651\n",
      "INFO:root:Test accuracy: 9913/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0264\n",
      "INFO:root:accuracy=0.9913\n",
      "INFO:root:Epoch: 11 (  0.0%) - Loss: 0.05512130260467529\n",
      "INFO:root:Epoch: 11 ( 81.8%) - Loss: 0.0037557038012892008\n",
      "INFO:root:Test accuracy: 9912/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0265\n",
      "INFO:root:accuracy=0.9912\n",
      "INFO:root:Epoch: 12 (  0.0%) - Loss: 0.03730277717113495\n",
      "INFO:root:Epoch: 12 ( 81.8%) - Loss: 0.013931994326412678\n",
      "INFO:root:Test accuracy: 9916/10000 ( 99.2%)\n",
      "INFO:root:loss=0.0267\n",
      "INFO:root:accuracy=0.9916\n",
      "INFO:root:Epoch: 13 (  0.0%) - Loss: 0.005963007919490337\n",
      "INFO:root:Epoch: 13 ( 81.8%) - Loss: 0.003455297090113163\n",
      "INFO:root:Test accuracy: 9912/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0266\n",
      "INFO:root:accuracy=0.9912\n",
      "INFO:root:Epoch: 14 (  0.0%) - Loss: 0.013700591400265694\n",
      "INFO:root:Epoch: 14 ( 81.8%) - Loss: 0.0014862313400954008\n",
      "INFO:root:Test accuracy: 9913/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0266\n",
      "INFO:root:accuracy=0.9913\n",
      "INFO:root:Epoch: 15 (  0.0%) - Loss: 0.011465010233223438\n",
      "INFO:root:Epoch: 15 ( 81.8%) - Loss: 0.0037046491634100676\n",
      "INFO:root:Test accuracy: 9913/10000 ( 99.1%)\n",
      "INFO:root:loss=0.0266\n",
      "INFO:root:accuracy=0.9913\n"
     ]
    }
   ],
   "source": [
    "! kubectl logs -f pytorchjob-mnist-master-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJgZgxgCYppv"
   },
   "source": [
    "Note that it may take a while when the image has to be pulled from the registry.\n",
    "Once the status for all pods is 'Running', it usually takes a few minutes, depending on the arguments and resources of the cluster.\n",
    "\n",
    "To delete the job, just execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qZd-Xt8SYppv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): pytorchjobs.kubeflow.org \"pytorchjob-mnist-1\" not found\n"
     ]
    }
   ],
   "source": [
    "! kubectl delete $PYTORCH_JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if the check to see if the pod is still up and running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): pods \"pytorchjob-mnist-master-1\" not found\n"
     ]
    }
   ],
   "source": [
    "! kubectl -n demo01 logs -f pytorchjob-mnist-master-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PytorchOperatorJobMNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
